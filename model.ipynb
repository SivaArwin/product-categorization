{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "import pickle\n",
    "from utils import download_nltk_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nltk dependencies, these are downloaded only once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/mohitlakshya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/mohitlakshya/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mohitlakshya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/mohitlakshya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "download_nltk_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>href</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Fresh Dates (Pack) (Approx 450 g - 500 g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Tender Coconut Cling Wrapped (1 pc) (Approx 90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Dates Imported (Approx 400 g - 500 g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Papaya (Each) (Approx. 800 g - 1600 g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Watermelon Kiran Big 1 pc (Approx. 2800 g - 40...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category         sub_category  \\\n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "\n",
       "                                                href  \\\n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "\n",
       "                                               items  \n",
       "0          Fresh Dates (Pack) (Approx 450 g - 500 g)  \n",
       "0  Tender Coconut Cling Wrapped (1 pc) (Approx 90...  \n",
       "0              Dates Imported (Approx 400 g - 500 g)  \n",
       "0             Papaya (Each) (Approx. 800 g - 1600 g)  \n",
       "0  Watermelon Kiran Big 1 pc (Approx. 2800 g - 40...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/jio_mart_items.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fruits & Vegetables' 'Premium Fruits' 'Dairy & Bakery' 'Staples'\n",
      " 'Snacks & Branded Foods' 'Beverages' 'Personal Care' 'Home Care'\n",
      " 'Apparel' 'Mom & Baby Care' 'Books' 'Pets' 'Kitchenware' 'Dining'\n",
      " 'Furnishing' 'Home Decor' 'Furniture' 'Home Appliances'\n",
      " 'Toys, Games & Fitness' 'Electrical' 'Bathroom & Laundry Accessories'\n",
      " 'Disposables' 'Stationery' 'Bags & Travel Luggage'\n",
      " 'Mops, Brushes & Scrubs' 'Auto Care' 'Garden & Outdoor'\n",
      " 'Carpentry & work accessories' 'Pooja Needs' 'Bathroom & Laundry'\n",
      " 'Industrial & Scientific Supplies' 'Building Supplies & Measuring Tools'\n",
      " 'Hardware & Plumbing' 'Home Safety & Automation'\n",
      " 'Kitchen & Bath Fixtures' 'Paint, Wall Treatments & Supplies'\n",
      " 'Power & Hand Tools' 'Handloom & Handicraft' 'Personal Wear' 'Men'\n",
      " 'Women' 'Boys' 'Girls' 'Junior Boys' 'Junior Girls' 'Infants' 'Tech'\n",
      " 'Mobiles & Tablets' 'TV & Speaker' 'Computers' 'Cameras'\n",
      " 'Kitchen Appliances' 'Personal Care & Grooming' 'Smart Devices' 'Gaming'\n",
      " 'Accessories' 'Phones' 'Office Products' 'Health Care Devices' 'Make-Up'\n",
      " 'Hair' 'Skin Care' 'Fragrances' 'Mom & Baby' \"Men's Grooming\"\n",
      " 'Tools & Appliances' 'Covid Essentials' 'Wellness' 'Fitness' 'Ayush'\n",
      " 'Treatments' 'Fine Jewellery']\n"
     ]
    }
   ],
   "source": [
    "print(df.sub_category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shop mapping\n",
    "vegetable_shop = ['Fruits & Vegetables', 'Premium Fruits']\n",
    "dairy_shop = ['Dairy & Bakery']\n",
    "kirana_shop = ['Staples', 'Snacks & Branded Foods', 'Bathroom & Laundry Accessories', 'Pooja Needs', 'Beverages', 'Mops, Brushes & Scrubs', 'Disposables']\n",
    "cloth_shop = ['Apparel', 'Personal Wear', 'Men', 'Women', 'Boys', 'Girls', 'Junior Boys', 'Junior Girls', 'Infants']\n",
    "pharmacy_shop = ['Personal Care', 'Personal Care & Grooming', 'Mom & Baby Care', 'Wellness', 'Fitness', 'Ayush', 'Covid Essentials', 'Health Care Devices', 'Treatments', 'Mom & Baby']\n",
    "beauty_shop = ['Make-Up', 'Hair', 'Skin Care', 'Fragrances', \"Men's Grooming\", 'Tools & Appliances']\n",
    "sports_shop = ['Toys, Games & Fitness']\n",
    "hardware_shop = ['Carpentry & work accessories', 'Industrial & Scientific Supplies', 'Building Supplies & Measuring Tools', 'Hardware & Plumbing', 'Home Safety & Automation', 'Kitchen & Bath Fixtures', 'Paint, Wall Treatments & Supplies']\n",
    "electronics_shop = ['Power & Hand Tools', 'Electrical', 'Home Appliances']\n",
    "mobile_shop = ['Tech', 'Mobiles & Tablets', 'TV & Speaker', 'Computers', 'Cameras', 'Kitchen Appliances', 'Smart Devices', 'Gaming', 'Phones', 'Accessories']\n",
    "stationary_shop = ['Office Products', 'Books', 'Stationery']\n",
    "jewellery_shop = ['Fine Jewellery']\n",
    "home_decor_shop = ['Furniture', 'Garden & Outdoor', 'Home Decor', 'Furnishing', 'Kitchenware', 'Dining']\n",
    "\n",
    "shops = {'vegetable_shop': vegetable_shop, 'dairy_shop': dairy_shop, 'kirana_shop': kirana_shop, 'cloth_shop': cloth_shop, 'pharamacy_shop': pharmacy_shop,\n",
    "        'beauty_shop': beauty_shop, 'sports_shop': sports_shop, 'hardware_shop': hardware_shop, 'electronics_shop': electronics_shop, 'mobile_shop': mobile_shop,\n",
    "        'stationary_shop': stationary_shop, 'jewellery_shop': jewellery_shop, 'furniture_shop': home_decor_shop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shop_name(x):\n",
    "    shop = None\n",
    "    for k, v in shops.items():\n",
    "        if x in v:\n",
    "            shop = k\n",
    "    if shop is None:\n",
    "        shop = 'other_shop' \n",
    "    return shop\n",
    "\n",
    "df['shop'] = df['sub_category'].apply(lambda x: shop_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158172, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have total 158172 product items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where there is no item description\n",
    "df = df.loc[~df['items'].isna(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Text data\n",
    "\n",
    "1. Remove non-alphanumeric characters\n",
    "2. Remove stop words\n",
    "3. Lemmatize each line of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>href</th>\n",
       "      <th>items</th>\n",
       "      <th>shop</th>\n",
       "      <th>clean_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Fresh Dates (Pack) (Approx 450 g - 500 g)</td>\n",
       "      <td>vegetable_shop</td>\n",
       "      <td>fresh date pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Tender Coconut Cling Wrapped (1 pc) (Approx 90...</td>\n",
       "      <td>vegetable_shop</td>\n",
       "      <td>tender coconut cling wrapped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Dates Imported (Approx 400 g - 500 g)</td>\n",
       "      <td>vegetable_shop</td>\n",
       "      <td>date imported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Papaya (Each) (Approx. 800 g - 1600 g)</td>\n",
       "      <td>vegetable_shop</td>\n",
       "      <td>papaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groceries</td>\n",
       "      <td>Fruits &amp; Vegetables</td>\n",
       "      <td>https://www.jiomart.com/c/groceries/fruits-veg...</td>\n",
       "      <td>Watermelon Kiran Big 1 pc (Approx. 2800 g - 40...</td>\n",
       "      <td>vegetable_shop</td>\n",
       "      <td>watermelon kiran big</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category         sub_category  \\\n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "0  Groceries  Fruits & Vegetables   \n",
       "\n",
       "                                                href  \\\n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "0  https://www.jiomart.com/c/groceries/fruits-veg...   \n",
       "\n",
       "                                               items            shop  \\\n",
       "0          Fresh Dates (Pack) (Approx 450 g - 500 g)  vegetable_shop   \n",
       "0  Tender Coconut Cling Wrapped (1 pc) (Approx 90...  vegetable_shop   \n",
       "0              Dates Imported (Approx 400 g - 500 g)  vegetable_shop   \n",
       "0             Papaya (Each) (Approx. 800 g - 1600 g)  vegetable_shop   \n",
       "0  Watermelon Kiran Big 1 pc (Approx. 2800 g - 40...  vegetable_shop   \n",
       "\n",
       "                    clean_items  \n",
       "0               fresh date pack  \n",
       "0  tender coconut cling wrapped  \n",
       "0                 date imported  \n",
       "0                        papaya  \n",
       "0          watermelon kiran big  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(words):\n",
    "    words = re.sub('[^a-zA-Z]', \" \", words)\n",
    "    text = words.lower().split()\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text, stop_words):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def lemmatize_words(text, lemma):\n",
    "    lem_text = [lemma.lemmatize(word) for word in text.split()]\n",
    "    return \" \".join(lem_text)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['approx', 'g', 'pc'])\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "df['clean_items'] = df['items'].apply(lambda x: clean_text(x))\n",
    "df['clean_items'] = df['clean_items'].apply(lambda x: remove_stop_words(x, stop_words))\n",
    "df['clean_items'] = df['clean_items'].apply(lambda x: lemmatize_words(x, lemma))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data\n",
    "df.to_parquet('./data/jio_mart_items_cleaned.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tagged document for Doc2Vec\n",
    "train_tag = train.apply(lambda x: TaggedDocument(words=word_tokenize(x['clean_items']), tags=[x.shop]), axis=1)\n",
    "test_tag = test.apply(lambda x: TaggedDocument(words=word_tokenize(x['clean_items']), tags=[x.shop]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035586"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a Doc2Vec model\n",
    "\n",
    "# dm = 0, using distributed bag of words\n",
    "# vector_size = 100, word embeddings shape\n",
    "# window = 2, predict every second word\n",
    "# sample = 0, threshold for which higher frequency words are randomly down sampled\n",
    "# min_count = 2, ignores all words with total frequency lower than this\n",
    "\n",
    "doc = Doc2Vec(dm=0, vector_size=100, min_count=2, window=2, sample=0)\n",
    "doc.build_vocab(train_tag)\n",
    "doc.corpus_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "doc.train(train_tag, total_examples=doc.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "doc.save('./models/model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building final vector feature for classifier\n",
    "def final_vector(model, input_docs):\n",
    "    targets, feature_vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in input_docs])\n",
    "    return targets, feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, x_train = final_vector(doc, train_tag)\n",
    "y_test, x_test = final_vector(doc, test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifer\n",
    "log_reg = LogisticRegression(n_jobs=4, C=5)\n",
    "log_reg.fit(x_train, y_train)\n",
    "y_pred = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.9443531048438093\n",
      "F1 score: 0.9441358111626635\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "print(f'Testing accuracy: {accuracy_score(y_pred, y_test)}')\n",
    "print(f'F1 score: {f1_score(y_test, y_pred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     beauty_shop       0.90      0.90      0.90      2723\n",
      "      cloth_shop       0.97      0.99      0.98      7759\n",
      "      dairy_shop       0.97      0.83      0.89       162\n",
      "electronics_shop       0.95      0.90      0.92      1458\n",
      "  furniture_shop       0.96      0.96      0.96      8561\n",
      "   hardware_shop       0.94      0.85      0.89       485\n",
      "  jewellery_shop       1.00      1.00      1.00        23\n",
      "     kirana_shop       0.93      0.95      0.94      7229\n",
      "     mobile_shop       0.97      0.97      0.97      4581\n",
      "      other_shop       0.96      0.95      0.95      3637\n",
      "  pharamacy_shop       0.90      0.89      0.90      5723\n",
      "     sports_shop       0.94      0.94      0.94      2491\n",
      " stationary_shop       0.95      0.93      0.94      2511\n",
      "  vegetable_shop       1.00      0.54      0.70        99\n",
      "\n",
      "        accuracy                           0.94     47442\n",
      "       macro avg       0.95      0.90      0.92     47442\n",
      "    weighted avg       0.94      0.94      0.94     47442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save logistic regression model\n",
    "model_name = 'logistic_regr_model.pkl'\n",
    "with open(f'./models/{model_name}', 'wb') as file:\n",
    "    pickle.dump(log_reg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloth_shop'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = doc.infer_vector('face'.split(' '))\n",
    "\n",
    "log_reg.predict(feature.reshape(1, -1)).tolist()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
